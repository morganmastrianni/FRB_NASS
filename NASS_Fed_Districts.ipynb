{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASS Statistics by Federal Reserve Bank District\n",
    "\n",
    "Which Federal Reserve Bank district has the most farmland? What commodities generate the most income in each district? Which district sells the most llamas? Using USDA 2022 Ag Census data and a nifty shapefile compiled by Colton Tousey of the Federal Reserve Bank of Kansas City, we can answer all of these questions, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gathering Data\n",
    "\n",
    "***DON'T RUN, it will take 3.5 hrs with good wifi***\n",
    "\n",
    "First, we need an API key from the USDA to query the NASS database. This is an untracked file in the GitHub repository for this project; it needs to be independently requested from the USDA by whoever wants to run this code.\n",
    "\n",
    "FedCounties.csv records the Federal Reserve Bank district for every county in the United States, along with state and county FIPS codes. NASS statistics also include FIPS codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import requests as req\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from alive_progress import alive_bar\n",
    "from time import sleep\n",
    "from wakepy import keep\n",
    "import polars.selectors as cs\n",
    "from great_tables import GT, style, loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_counties_df = pl.read_csv(\"FedCounties.csv\")\n",
    "fed_counties_df = fed_counties_df.filter(\n",
    "    (pl.col(\"STATEFP\") != 78) & (pl.col(\"STATEFP\") != 72)\n",
    ")  # excl. PR and U.S. Virgin Islands\n",
    "tuples = []\n",
    "\n",
    "for dist in range(1, 13):\n",
    "    filtered = fed_counties_df.filter(fed_counties_df[\"District\"] == dist)\n",
    "    tuples.extend(\n",
    "        zip(\n",
    "            filtered[\"District\"].to_list(),\n",
    "            filtered[\"STATEFP\"].to_list(),\n",
    "            filtered[\"COUNTYFP\"].to_list(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "tuples = [(t[0], str(t[1]).zfill(2), str(t[2]).zfill(3)) for t in tuples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the unique county, state, Fed district pairs. The next step is to gather ALL 2022 Census data for every county and add a new variable to the USDA data: \"District\".\n",
    "\n",
    "***DON'T RUN, continue from 2***\n",
    "\n",
    "Note: Puerto Rico and the U.S. Virgin Islands are excluded (part of the N.Y. Fed district), there was trouble with querying those state FIPS codes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "url = \"https://quickstats.nass.usda.gov/api/api_GET\"\n",
    "api_key = os.getenv(\"NASS_api_key\")\n",
    "\n",
    "district_dfs = []\n",
    "with keep.presenting():  # took approx. 3:29 hrs\n",
    "    for dist in range(1, 13):\n",
    "        pairs = [\n",
    "            (state, county) for district, state, county in tuples if district == dist\n",
    "        ]\n",
    "\n",
    "        county_dfs = []\n",
    "        with alive_bar(len(pairs), title=\"Pairs\") as bar:\n",
    "            for state, county in pairs:\n",
    "                bar()\n",
    "                raw = req.get(\n",
    "                    url,\n",
    "                    params={\n",
    "                        \"key\": api_key,\n",
    "                        \"state_fips_code\": state,\n",
    "                        \"county_code\": county,\n",
    "                        \"agg_level_desc\": \"COUNTY\",\n",
    "                        \"source_desc\": \"CENSUS\",\n",
    "                        \"year\": 2022,\n",
    "                        \"format\": \"json\",\n",
    "                    },\n",
    "                ).text\n",
    "                sleep(2)\n",
    "\n",
    "                try:\n",
    "                    content = json.loads(raw)\n",
    "                except json.decoder.JSONDecodeError as e:\n",
    "                    print(raw)\n",
    "                    raise e\n",
    "\n",
    "                if \"error\" in content:\n",
    "                    print(state, county)\n",
    "                    print(content[\"error\"])\n",
    "                    continue\n",
    "\n",
    "                county_df = pl.DataFrame(json.loads(raw)[\"data\"])\n",
    "                county_df = county_df.select(\n",
    "                    [pl.col(c) for c in sorted(county_df.columns)]\n",
    "                )\n",
    "                county_dfs.append(county_df)\n",
    "\n",
    "        district_df = pl.concat(county_dfs)\n",
    "        district_df = district_df.with_columns(pl.lit(dist).alias(\"District\"))\n",
    "        district_dfs.append(district_df)\n",
    "\n",
    "NASS_pull = pl.concat(district_dfs)\n",
    "NASS_pull.write_parquet(\"NASS_pull.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect data on Puerto Rico in a separate query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (45_633, 40)\n",
      "┌────────┬─────────────┬────────────────┬──────────┬───┬─────────────┬──────┬───────┬──────────┐\n",
      "│ CV (%) ┆ Value       ┆ agg_level_desc ┆ asd_code ┆ … ┆ week_ending ┆ year ┆ zip_5 ┆ District │\n",
      "│ ---    ┆ ---         ┆ ---            ┆ ---      ┆   ┆ ---         ┆ ---  ┆ ---   ┆ ---      │\n",
      "│ str    ┆ str         ┆ str            ┆ str      ┆   ┆ str         ┆ i64  ┆ str   ┆ i32      │\n",
      "╞════════╪═════════════╪════════════════╪══════════╪═══╪═════════════╪══════╪═══════╪══════════╡\n",
      "│ 22.1   ┆ 28,813,951  ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆             ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 8.0    ┆ 48,301,595  ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆             ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 11.0   ┆ 41,205,033  ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆             ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 13.1   ┆ 71,583,387  ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆             ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 4.8    ┆ 107,130,970 ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆             ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ …      ┆ …           ┆ …              ┆ …        ┆ … ┆ …           ┆ …    ┆ …     ┆ …        │\n",
      "│ 16.9   ┆ 49          ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆             ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 7.1    ┆ 173         ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆             ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 9.5    ┆ 439         ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆             ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 19.0   ┆ 15          ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆             ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 17.9   ┆ 14          ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆             ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "└────────┴─────────────┴────────────────┴──────────┴───┴─────────────┴──────┴───────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# load_dotenv()\n",
    "# url = \"https://quickstats.nass.usda.gov/api/api_GET\"\n",
    "# api_key = os.getenv(\"NASS_api_key\")\n",
    "\n",
    "raw = req.get(\n",
    "    url,\n",
    "    params={\n",
    "        \"key\": api_key,\n",
    "        \"agg_level_desc\": \"PUERTO RICO & OUTLYING AREAS\",\n",
    "        \"state_name\": \"PUERTO RICO\",\n",
    "        \"source_desc\": \"CENSUS\",\n",
    "        \"year\": 2022,\n",
    "        \"format\": \"json\",\n",
    "    },\n",
    ").text\n",
    "\n",
    "try:\n",
    "    content = json.loads(raw)\n",
    "except json.decoder.JSONDecodeError as e:\n",
    "    print(raw)\n",
    "    raise e\n",
    "\n",
    "pr_df = pl.DataFrame(json.loads(raw)[\"data\"])\n",
    "pr_df = pr_df.select(\n",
    "    [pl.col(c) for c in sorted(pr_df.columns)]\n",
    ")\n",
    "NASS_pull_pr = pr_df.with_columns(pl.lit(2).alias(\"District\"))\n",
    "NASS_pull_pr.write_parquet(\"NASS_pull_pr.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final dataset is stored as a .parquet file; this is very similar to a CSV file but it takes up a fraction of the space. There are over 3 million rows in \"NASS_pull.parquet; a CSV file with that many rows costs actual money to upload to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning\n",
    "\n",
    "Some values in the final dataset are not actual values, so we need to filter these rows out. Then, we can aggregate our data to get rid of extraneous information, which at this point is any and all columns excluding \"short_desc\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3_918_933, 40)\n",
      "┌────────┬────────────┬────────────────┬──────────┬───┬─────────────┬──────┬───────┬──────────┐\n",
      "│ CV (%) ┆ Value      ┆ agg_level_desc ┆ asd_code ┆ … ┆ week_ending ┆ year ┆ zip_5 ┆ District │\n",
      "│ ---    ┆ ---        ┆ ---            ┆ ---      ┆   ┆ ---         ┆ ---  ┆ ---   ┆ ---      │\n",
      "│ str    ┆ str        ┆ str            ┆ str      ┆   ┆ str         ┆ i64  ┆ str   ┆ i32      │\n",
      "╞════════╪════════════╪════════════════╪══════════╪═══╪═════════════╪══════╪═══════╪══════════╡\n",
      "│ (L)    ┆ 12,612,000 ┆ COUNTY         ┆ 10       ┆ … ┆             ┆ 2022 ┆       ┆ 1        │\n",
      "│ 8.3    ┆ 272        ┆ COUNTY         ┆ 10       ┆ … ┆             ┆ 2022 ┆       ┆ 1        │\n",
      "│ (D)    ┆ (D)        ┆ COUNTY         ┆ 10       ┆ … ┆             ┆ 2022 ┆       ┆ 1        │\n",
      "│ (L)    ┆ 2          ┆ COUNTY         ┆ 10       ┆ … ┆             ┆ 2022 ┆       ┆ 1        │\n",
      "│ (D)    ┆ (D)        ┆ COUNTY         ┆ 10       ┆ … ┆             ┆ 2022 ┆       ┆ 1        │\n",
      "│ …      ┆ …          ┆ …              ┆ …        ┆ … ┆ …           ┆ …    ┆ …     ┆ …        │\n",
      "│ 16.9   ┆ 49         ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆            ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 7.1    ┆ 173        ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆            ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 9.5    ┆ 439        ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆            ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 19.0   ┆ 15         ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆            ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "│ 17.9   ┆ 14         ┆ PUERTO RICO &  ┆          ┆ … ┆             ┆ 2022 ┆       ┆ 2        │\n",
      "│        ┆            ┆ OUTLYING AREAS ┆          ┆   ┆             ┆      ┆       ┆          │\n",
      "└────────┴────────────┴────────────────┴──────────┴───┴─────────────┴──────┴───────┴──────────┘\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'endd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mconcat(dfs)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mendd\u001b[49m\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;241m~\u001b[39mpl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(D\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m)|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(Z\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwith_columns(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(pl\u001b[38;5;241m.\u001b[39mFloat64))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'endd' is not defined"
     ]
    }
   ],
   "source": [
    "df_big = pl.read_parquet(\"NASS_pull.parquet\")\n",
    "df_pr = pl.read_parquet(\"NASS_pull_pr.parquet\")\n",
    "dfs = [df_big, df_pr]\n",
    "df = pl.concat(dfs)\n",
    "df = df.filter(~pl.col(\"Value\").str.contains(r\"\\(D\\)|\\(Z\\)\"))\n",
    "df = df.with_columns(pl.col(\"Value\").str.replace_all(\",\", \"\").cast(pl.Float64))\n",
    "\n",
    "district_dfs = []\n",
    "\n",
    "for dist in df.partition_by(\"District\"):\n",
    "    district_df = dist.group_by(\"short_desc\").agg(\n",
    "        [\n",
    "            pl.when(pl.col(\"short_desc\").str.contains(\"PCT\"))\n",
    "            .then(pl.col(\"Value\").median())\n",
    "            .otherwise(pl.col(\"Value\").sum())\n",
    "            .alias(\"District_Total\"),\n",
    "            pl.mean(\"District\").cast(pl.Int32),\n",
    "        ]\n",
    "    )\n",
    "    district_dfs.append(district_df)\n",
    "\n",
    "df = pl.concat(district_dfs)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We take the median percentages (robust to outliers) across all counties in the dataset. The interpretation of these values is not super intuitive. Each mean percent is the \"average percent ___ for all counties in the district\", not the percent ___ for the district.\n",
    "\n",
    "Also, the conditional aggregation creates a dataframe where \"District_Total\" is actually a column of lists. We resolve this in step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyzing\n",
    "\n",
    "***RUN FROM HERE***\n",
    "\n",
    "To filter through the data and find commodities that we want to know more about, we can use a keyword search approach applied to the short description of the data item. Some examples are presented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = range(1, 13)\n",
    "# districts = [10, 11, 12]\n",
    "\n",
    "keyword_list = []\n",
    "excl_keyword_list = []\n",
    "\n",
    "# k1 = [\"acres\", \"ag land\"]\n",
    "# keyword_list.append(k1)\n",
    "# ek1 = [\n",
    "#     \"treated\",\n",
    "#     \"wood\",\n",
    "#     \"pasture\",\n",
    "#     \"reserv\",\n",
    "#     \"to\",\n",
    "#     \"crop\",\n",
    "#     \"pct\",\n",
    "#     \"irrigated\",\n",
    "#     \"organic\",\n",
    "# ]\n",
    "# excl_keyword_list.append(ek1)\n",
    "\n",
    "# k2 = [\"number\", \"ag land\"]\n",
    "# keyword_list.append(k2)\n",
    "# ek2 = [\"wood\", \"pasture\", \"reserv\", \"to\", \"crop\", \"pct\", \"irrigated\", \"organic\"]\n",
    "# excl_keyword_list.append(ek2)\n",
    "\n",
    "# k3 = [\"number\", \"asset value\", \"\\$\"]\n",
    "# keyword_list.append(k3)\n",
    "# ek3 = []\n",
    "# excl_keyword_list.append(ek3)\n",
    "\n",
    "# k4 = [\"income\", \"receipts\", \"\\$\"]\n",
    "# keyword_list.append(k4)\n",
    "# ek4 = [\"operation\", \"other\", \"dividends\", \"insurance\", \"forest\", \"tourism\"]\n",
    "# excl_keyword_list.append(ek4)\n",
    "\n",
    "# k5 = [\"income\", \"net\", \"\\$\"]\n",
    "# keyword_list.append(k5)\n",
    "# ek5 = [\"gain\", \"loss\", \"/ operation\"]\n",
    "# excl_keyword_list.append(ek5)\n",
    "\n",
    "commodity_keywords = [\"sales, measured in \\$\"]\n",
    "keyword_list.append(commodity_keywords)\n",
    "commodity_excl_keywords = [\"totals\"]\n",
    "excl_keyword_list.append(commodity_excl_keywords)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for incl, excl in zip(keyword_list, excl_keyword_list):\n",
    "    custom = df.filter(\n",
    "        [pl.col(\"short_desc\").str.to_lowercase().str.contains(k.lower()) for k in incl],\n",
    "        *[\n",
    "            ~pl.col(\"short_desc\").str.to_lowercase().str.contains(exk.lower())\n",
    "            for exk in excl\n",
    "        ],\n",
    "        pl.col(\"District\").is_in(districts),\n",
    "    )\n",
    "    dfs.append(custom)\n",
    "\n",
    "custom = pl.concat(dfs)\n",
    "custom = custom.with_columns(pl.col(\"District_Total\").list.unique().list.first())\n",
    "\n",
    "custom.write_parquet(\"custom_df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know exactly which data items we would like included in a final table, then we can move on to 4. If some extra analysis needs doing, then go to step 3a first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. More Analyzing\n",
    "\n",
    "If there are some secondary characteristics we want more information on, such as which commodities generate the most cash sales in each district, then some more work needs to be done before a dataframe will be ready for final formatting. Below we find the top 10 highest value commodities in each district, per our earlier keyword search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (120, 3)\n",
      "┌─────────────────────────────────┬────────────────┬──────────┐\n",
      "│ short_desc                      ┆ District_Total ┆ District │\n",
      "│ ---                             ┆ ---            ┆ ---      │\n",
      "│ str                             ┆ f64            ┆ i32      │\n",
      "╞═════════════════════════════════╪════════════════╪══════════╡\n",
      "│ MILK - SALES, MEASURED IN $     ┆ 1.4799e9       ┆ 1        │\n",
      "│ FIELD CROPS, OTHER, INCL HAY -… ┆ 4.93656e8      ┆ 1        │\n",
      "│ CATTLE, INCL CALVES - SALES, M… ┆ 2.11866e8      ┆ 1        │\n",
      "│ MAPLE SYRUP - SALES, MEASURED … ┆ 1.37478e8      ┆ 1        │\n",
      "│ GRAIN - SALES, MEASURED IN $    ┆ 8.7437e7       ┆ 1        │\n",
      "│ …                               ┆ …              ┆ …        │\n",
      "│ CORN - SALES, MEASURED IN $     ┆ 1.4037e9       ┆ 12       │\n",
      "│ COTTON, LINT & SEED - SALES, M… ┆ 1.2953e9       ┆ 12       │\n",
      "│ RICE - SALES, MEASURED IN $     ┆ 7.23593e8      ┆ 12       │\n",
      "│ CUT CHRISTMAS TREES & SHORT TE… ┆ 4.21853e8      ┆ 12       │\n",
      "│ GRAIN, OTHER - SALES, MEASURED… ┆ 4.05641e8      ┆ 12       │\n",
      "└─────────────────────────────────┴────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.read_parquet(\"custom_df.parquet\")\n",
    "\n",
    "district_dfs = []\n",
    "\n",
    "for dist in df.partition_by(\"District\"):\n",
    "    district_df = dist.sort(\"District_Total\", descending=True).head(10)\n",
    "    district_dfs.append(district_df)\n",
    "\n",
    "df = pl.concat(district_dfs)\n",
    "print(df)\n",
    "\n",
    "df.write_parquet(\"custom_df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Table Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\AppData\\Local\\Temp\\ipykernel_28580\\2829481187.py:19: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  df_pivot = df.pivot(\n"
     ]
    },
    {
     "ename": "ColumnNotFoundError",
     "evalue": "short_desc\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'select' <---\nDF [\"Description\", \"Boston\", \"New York (excl. PR and U.S. VI)\", \"Philadelphia\"]; PROJECT */13 COLUMNS",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Sort the values for this district in descending order\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m sorted_data \u001b[38;5;241m=\u001b[39m \u001b[43mdistrict_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshort_desc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistrict\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m sorted_data \u001b[38;5;241m=\u001b[39m sorted_data\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;241m~\u001b[39mpl\u001b[38;5;241m.\u001b[39mcol(district)\u001b[38;5;241m.\u001b[39mis_null())\n\u001b[0;32m     43\u001b[0m sorted_data \u001b[38;5;241m=\u001b[39m sorted_data\u001b[38;5;241m.\u001b[39msort(by\u001b[38;5;241m=\u001b[39mdistrict, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\morga\\Documents\\Code\\FED_districts_NASS_query\\.venv\\Lib\\site-packages\\polars\\dataframe\\frame.py:9364\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[1;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[0;32m   9264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mselect\u001b[39m(\n\u001b[0;32m   9265\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexprs: IntoExpr \u001b[38;5;241m|\u001b[39m Iterable[IntoExpr], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs: IntoExpr\n\u001b[0;32m   9266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   9267\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   9268\u001b[0m \u001b[38;5;124;03m    Select columns from this DataFrame.\u001b[39;00m\n\u001b[0;32m   9269\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9362\u001b[0m \u001b[38;5;124;03m    └──────────────┘\u001b[39;00m\n\u001b[0;32m   9363\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 9364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\morga\\Documents\\Code\\FED_districts_NASS_query\\.venv\\Lib\\site-packages\\polars\\lazyframe\\frame.py:2056\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[1;34m(self, type_coercion, _type_check, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _check_order, _eager, **_kwargs)\u001b[0m\n\u001b[0;32m   2054\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[0;32m   2055\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[1;32m-> 2056\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mColumnNotFoundError\u001b[0m: short_desc\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'select' <---\nDF [\"Description\", \"Boston\", \"New York (excl. PR and U.S. VI)\", \"Philadelphia\"]; PROJECT */13 COLUMNS"
     ]
    }
   ],
   "source": [
    "df = pl.read_parquet(\"custom_df.parquet\")\n",
    "\n",
    "df = df.pivot(\"District\", values=cs.starts_with(\"District_Total\"))\n",
    "\n",
    "df = df.rename(dict)\n",
    "df = df.with_columns(pl.col(\"Description\").str.to_titlecase())\n",
    "print(df)\n",
    "\n",
    "# refer to NASS for units\n",
    "gt_df = GT(df)\n",
    "\n",
    "dist_cols = [\n",
    "    \"Boston\",\n",
    "    \"New York (excl. PR and U.S. VI)\",\n",
    "    \"Philadelphia\",\n",
    "    \"Cleveland\",\n",
    "    \"Richmond\",\n",
    "    \"Atlanta\",\n",
    "    \"Chicago\",\n",
    "    \"St. Louis\",\n",
    "    \"Minneapolis\",\n",
    "    \"Kansas City\",\n",
    "    \"Dallas\",\n",
    "    \"San Francisco\",\n",
    "]\n",
    "\n",
    "gt_df = gt_df.tab_spanner(label=\"District\", columns=dist_cols).tab_style(\n",
    "    style=style.text(size=\"9px\", font=\"Helvetica\"),\n",
    "    locations=loc.body(columns=\"Description\"),\n",
    ")\n",
    "\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, I think a good amount of hard-coding is needed for table formatting; districts will have different top-production commodities, so how do we want to display that information? It's tougher to decide than when you are comparing particular commodity classes across districts..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
